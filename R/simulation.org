#+SETUPFILE: https://fniessen.github.io/org-html-themes/org/theme-bigblow.setup
#+TITLE: Ye Olde (Literate) SVEIRD Model (optionally with BDA)
#+AUTHOR: Bryce Carson
# Copyright © 2024 Bryce Carson

This is a literate version of the SVEIRD "raster" simulation with Bayesian data assimilation.

* Introduction
The purpose of this literate program is to study, again, the flow control and
algorithm in the old implementation of spatialEpisim's simulation core. The
reason I am doing this is because the new core, the refactored version which is
an R package called /spatialEpisim.foundation/, does not operate as expected.

#+begin_comment
Following a literate re-write of the old code until I discover where within
the new code it deviates unintentionally will help me resole the error.

Using the old code, re-organized into a literate program, will help me determine
what aspects of the implementations differ at a finer level than I may have been
able to see otherwise.
#+end_comment

** Reading this document
This document is composed of various top-level sections and sub-sections. The
top-level sections are given their own virtual page, and the heading
corresponding to that section is displayed as a title on that virtual page.
Sections below that level are collapsible.

Not all code blocks have names, and not all named code blocks have their name
displayed in the rendered document.

Improvements could be made to the JavaScript and CSS used to render this page
and add dynamic elements to it. For now these are not in-progress.

** Should the old code be made noisy in the literate document?
Or should it perfectly replicate what is committed (once tangled)?

To ensure that I reproduce the old code exactly in this literate program I will
tangle the program in two or three different ways.

1. Uncomment statements which are commented which only print values and have no
   side-effects otherwise.
2. No change.
3. Remove all "dead code" (ie. commented code).

I'm not sure how I will do this yet, but it will happen and be documented in one
way or another. I might make use of the ~withAutoprint~ form of the ~source~
function.

*** DONE Uncomment diagnostic print statements which were written during the initial implementation (before I joined the project)
CLOSED: [2024-10-09 Wed 00:05]
I won't bother with this because the number of print statements is way too many
and its too noisy to be really helpful for me. What I'll do is run the
(slightly) modified verison of the original code interactively, referring to the
old print statements and manually running which statemetns I feel will help me
determine what the results should look like.

*** DONE No change
CLOSED: [2024-10-09 Wed 00:05]
This is achieved, and I have diffs which prove that there are only insignificant
whitespace changes between the old file and the tangled file produced from this
literate source document.

#+begin_src sh :exports code :eval no :shebang #!/usr/bin/env bash
  if diff --ignore-all-space rasterSimulation_DA.R literateRasterSimulationWithDA.R; then
    echo "Equivalent";
  fi
#+end_src

This shell script will no longer report "Equivalent" because there are now more
changes than in just whitespace, but see [[Remove all dead code]] to view an updated
diff command which accounts for that.

*** Remove all dead code
The organization of the old code in a single file with poor commenting practices
makes understanding the code difficult at times. To make the literate program
more understandable, comments of various types have been removed, which makes
the diff of the two files non-equivalent unless comments are ignored.

If you have never seen a diff before, [[http://www.pixelbeat.org/programming/diffs/][check out this webpage]].

#+begin_src bash :exports both :eval yes :shebang #!/usr/bin/env bash :results verbatim
  removecomments() {
    awk '!/^\s+?#/' "$1"
  }

  FILE_A=$(mktemp)
  FILE_B=$(mktemp)
  removecomments rasterSimulation_DA.R > "$FILE_A"
  removecomments literateRasterSimulationWithDA.R > "$FILE_B"
  if diff --ignore-all-space "$FILE_A" "$FILE_B"; then
    echo "Equivalent";
  fi
#+end_src

#+RESULTS:
#+begin_example diff
273d272
< 
276,277c275
<   for (t in 1:timestep)
<   {					# time increments
---
> for (t in 1:timestep) {
288d285
< 
313d309
< 
322d317
< 
336d330
< 
342d335
< 
529a523
> 
531c525
<   }   # time increments
---
> }
572d565
< 
#+end_example

* The Olde Code's Organization
The old code can be thought of as being organized into three major sections:
1. its dependenecies
2. its actual function definition
3. examples of using the function

#+begin_src R :noweb no-export :tangle literateRasterSimulationWithDA.R
  <<dependencies>>

  <<function definition>>

  <<examples>>
#+end_src

** Dependencies (packages, source files, and package options)
#+name: dependencies
#+begin_src R :noweb no-export
  options(conflicts.policy = list(warn = FALSE))
  shhh <- suppressPackageStartupMessages # It's a library, so shhh!
  shhh(library(av))
  shhh(library(countrycode))
  shhh(library(cptcity))
  shhh(library(lattice))
  shhh(library(lubridate))
  shhh(library(magick))
  shhh(library(Matrix))
  shhh(library(rasterVis))
  shhh(library(rstudioapi))
  shhh(library(readxl))
  shhh(library(sp))
  shhh(library(sf))     # classes and functions for vector data
  shhh(library(terra, warn.conflicts=FALSE))
  shhh(library(writexl))

  <<source dependencies>>

  #-------------------------------------------------------------------------------------#
  # Compartmental model simulation with an option to include Bayesian Data Assimilation #
  #-------------------------------------------------------------------------------------#
#+end_src

#+RESULTS: dependencies

The following additional source files were included.

#+name: source dependencies
#+begin_src R
  # source("R/rasterStack.R")  # This code generates the base RasterStack/RasterBrick
  source("R/rasterPlot.R")   # This code generates the .png and .mp4 files for RasterStack
  source("R/distwtRaster.R") # This code sets the Euclidean distance and the weight matrix
#+end_src

** Simulation (optionally with data assimilation)
*** The function header and its arguments
#+name: function definition
#+begin_src R :noweb no-export :noweb-prefix no
  SpatialCompartmentalModelWithDA <- <<function arguments>>
  {
    <<function body>>
  } # End of function
#+end_src

The original definition of the function had many arguments, many of them badly
named (in my opinion).

#+name: function arguments
#+begin_src R
  function(model, stack, startDate, selectedCountry, directOutput,
           rasterAgg, alpha, beta, gamma, sigma, delta, radius, lambda,
           timestep, seedFile, seedRadius, deterministic, isCropped,
           level1Names, DA = F, sitRepData, dataI, dataD, varCovarFunc,
           QVar, QCorrLength, nbhd, psiDiag)
#+end_src

*** The function body
The body of the function is documented in higher levels of sectioning, given
its length, beginning with [[The Main Loop]].

** Examples
The examples don't work, in my personal experience. Really, they don't work as
they were written. The file was only useful when integrated (as it was) with the
Shiny application (as it was). See the section [[Broken Examples]] in [[Miscellany]].

* The Main Loop
SEI-type simulations are implemented within a single loop.

Inside the loop, components of an object named =stack$rasterStack= are iterated
upon, and intermediate results are stored in an object named =allRasters= at the
end of each iteration. Before the loop begins some necessary setup is performed.

#+begin_comment
=stack$rasterStack= is a misnomer; =rasterStack= is not actually an object of
class =RasterStack=. Further, the =stack= object has many redundant components
which are unused throughout the simulation. This aside, this is the object
manipulated during the main loop.
#+end_comment

The setup before the main loop of the simulation is simple enough: the
components of =stack$rasterStack= are SEI-type compartments which are assigned
to similarly named objects, unpacking them; a data frame is created to store the
results of each iteration; an important object named =p= is created; finally,
the inital state of the simulation is "seeded".

#+begin_src R :noweb no-export :noweb-ref function body
  <<setup before the main loop of the simulation>>

  ###################################
  ## MAIN LOOP FOR TIME INCREMENTS ##
  ###################################
  allRasters <- vector(mode = "list", length = timestep)

  for (t in 1:timestep) {
    <<write the current state of the simulation into the summary table>>

    <<prepare some data before continuing with the actions of this iteration>>

    <<recalculate the values within every cell of the raster and store them>>

    <<write the daily incidences to the summary table and store the sum of compartments for writing at the beginning of the next iteration>>

    <<Bayesian data assimilation part two>>

    allRasters[[t]] <- stack
  }

  <<print allRasters and return the results>>
#+end_src

** setup before the main loop of the simulation
Further discussion of "seeding" is in the [[seed the simulation]] section.

#+name: setup before the main loop of the simulation
#+begin_src R :noweb no-export
  <<unlink, delete, and recreate the MP4 output directory>>

  inputISO <- countrycode(selectedCountry, origin = 'country.name', destination = 'iso3c') #Converts country name to ISO Alpha

  Susceptible <- stack$rasterStack$Susceptible
  Vaccinated <- stack$rasterStack$Vaccinated
  Exposed <- stack$rasterStack$Exposed
  Infected <- stack$rasterStack$Infected
  Recovered <- stack$rasterStack$Recovered
  Dead <- stack$rasterStack$Dead

  Inhabitable <- stack$rasterStack$Inhabitable
  Level1Raster <- stack$rasterStack$Level1Raster

  Level1Identifier <- stack$Level1Identifier

  <<print statements №1>>

  names <- c("Date", "N", "S", "V", "E", "I", "R", "D",
             "newV", "newE", "newI", "newR","newD", "cumE", "cumI", "Alpha", "Beta", "Gamma", "Sigma", "Delta",
             "Radius", "Lambda", "Model", "DA")

  summary <- data.frame(matrix(data = 0, ncol = length(names), nrow = timestep))

  colnames(summary) <- names

  nrows <- nrow(stack$rasterStack) #
  ncols <- ncol(stack$rasterStack) #

  p <- nrows * ncols

  <<seed the initial states from the provided seed data>>

  <<print statements №1.5>>

  valSusceptible <- terra::as.matrix(Susceptible, wide = TRUE)
  valVaccinated <- terra::as.matrix(Vaccinated, wide = TRUE)
  valExposed <- terra::as.matrix(Exposed, wide = TRUE)
  valInfected <- terra::as.matrix(Infected, wide = TRUE)
  valRecovered <- terra::as.matrix(Recovered, wide = TRUE)
  valDead <- terra::as.matrix(Dead, wide = TRUE)
  <<print statements №2>>

  <<remove the seeded VEIRD compartments from the S compartment>>

  datarow <- 1 # pre-allocating the row from which we read the data to assimilate each week
  cumVaccinated <- round(sumV)
  cumExposed <- round(sumE)
  cumInfected <- round(sumI)
  cumRecovered <- round(sumR)
  cumDead <- round(sumD)

  cumIncidence <- round(sumI)

  <<setup to perform when using Bayesian data assimilation>>
#+end_src

** Create the susceptible layer
This is the confusing /proportion/ that I wanted to talk to Ashok about during
our meeting on Monday afternoon, but which I couldn't find in the Org file or
rendered HTML at the time.

The Susceptible raster can be referred to as the /population/ raster before the
final reassignment final assignment statement in this code block (in "the
confusing part"). Before then it is actually the population raster data from
WorldPop. The other rasters, VEIRD, will be either empty or have seeded values
(depending on the input data used for seeding the model and the user options at
run-time).

#+name: remove the seeded VEIRD compartments from the S compartment
#+begin_src R
  sumS <- sum(values(Susceptible))
  sumV <- sum(values(Vaccinated))
  sumE <- sum(values(Exposed))
  sumI <- sum(values(Infected))
  sumR <- sum(values(Recovered))
  sumD <- sum(values(Dead))

  ## print(sumS); print(sumV); print(sumE); print(sumI); print(sumR); print(sumD)

  <<the confusing part>>

  print(paste("Susceptible Count after removing initial seed values: ", sum(values(Susceptible))))
#+end_src

We'll focus on just the confusing part now.

#+name: the confusing part
#+begin_src R
  propVaccinated <- sumV/sumS
  propExposed <- sumE/sumS
  propInfected <- sumI/sumS
  propRecovered <- sumR/sumS
  propDead <- sumD/sumS

  <<print statements №3>>

  Susceptible <- Susceptible - (Susceptible*propVaccinated) - (Susceptible*propExposed) - (Susceptible*propInfected) - (Susceptible*propRecovered) - (Susceptible*propDead)
#+end_src

It appears to me that if a small pocket of vaccinations were completed, say a
ring vaccination compaign was completed around a village with an outbreak of
Ebola virus, that this assignment statement takes the global sum of the
vaccinations (if two rings are made, these become one value [for example 912
vaccinations across a province]) and calculates the percentage of vaccinated
persons among the whole simulated area. The susceptible persons in any given
cell throughout the simulation are then calculated as the population in that
cell less the product of the calculated percentage and the population in that
cell.

#+begin_src R :session *R example*
  library(tidyverse)
  library(terra)

  v <- vect(system.file("ex/lux.shp", package="terra"))
  r <- rast(system.file("ex/elev.tif", package="terra"))

  r2 <- rast(r)
  r2[46:50, 45] <- 1:5

  sum <- \(...) base::sum(..., na.rm = TRUE)
  population <- sum(values(r))
  r <- r - (r * (sum(values(r2)) / population))
  population == sum(values(r))
#+end_src

Manually examing the results, it is clear that the proportion of vaccinated
persons in just a few cells is subtracted from the population in /every cell/,
effectively averaging the number of vaccinated persons across the entire region
under study. This is done with every model compartment, so seeding values in
specific cells is interrupted and overriden, actually! Definitely not correct,
right?

[[file:~/Documents/src/r/spatialEpisim.stable/proof.ods]["proof" spreadsheet file]]

I'm not confused any longer, now I'm just absolutely certain that my
implementation is more accurate in too many ways /to not completely switch to it
once it is ready/.

** write the current state of the simulation into the summary table
#+begin_src R :noweb-ref write the current state of the simulation into the summary table
  summary[t, 1]  <- toString(as.Date(startDate) + days(t - 1)) # Print the date at each time step
  summary[t, 2]  <- round(sumS + sumV + sumE + sumI + sumR + sumD)
  summary[t, 3]  <- round(sumS)
  summary[t, 4]  <- round(sumV)            # Absorbing state
  summary[t, 5]  <- round(sumE)            # This is the prevalence (active exposed cases) at time t, NOT the cumulative sum
  summary[t, 6]  <- round(sumI)            # This is the prevalence (active infectious cases) at time t, NOT the cumulative sum
  summary[t, 7]  <- round(cumRecovered)    # round(sumR)   # Absorbing state
  summary[t, 8]  <- round(cumDead)         # round(sumD)   # Absorbing state
#+end_src

The ninth through thirteenth values are not available yet, supposedly, and are
written into this table at the very end of the timestep.

#+begin_src R :noweb-ref write the current state of the simulation into the summary table
  summary[t, 14]  <- round(cumExposed)
  summary[t, 15]  <- round(cumInfected)
  summary[t, 16]  <- alpha
  summary[t, 17]  <- beta
  summary[t, 18]  <- gamma
  summary[t, 19]  <- sigma
  summary[t, 20]  <- delta
  summary[t, 21]  <- radius
  summary[t, 22]  <- lambda
  summary[t, 23]  <- model
#+end_src

** others
#+name: prepare some data before continuing with the actions of this iteration
#+begin_src R :noweb no-export
  <<Convert the components of the RasterStack to wide matrices>>
  <<create empty values used hereafter in other calculations>>
#+end_src

#+name: Convert the components of the RasterStack to wide matrices
#+begin_src R
  valInhabitable <- terra::as.matrix(Inhabitable, wide = TRUE)
  valSusceptible <- terra::as.matrix(Susceptible, wide = TRUE)
  valVaccinated <- terra::as.matrix(Vaccinated, wide = TRUE)
  valExposed <- terra::as.matrix(Exposed, wide = TRUE)
  valInfected <- terra::as.matrix(Infected, wide = TRUE)
  valRecovered <- terra::as.matrix(Recovered, wide = TRUE)
  valDead <- terra::as.matrix(Dead, wide = TRUE)
#+end_src

#+name: create empty values used hereafter in other calculations
#+begin_src R
  nextSusceptible <- nextVaccinated <- nextExposed <- nextInfected <- nextRecovered <- nextDead <- matrix(0, nrows, ncols, byrow = T)
  pSusceptible <- newVaccinated <- nearbyInfected <- newExposed <- newInfected <- newRecovered <- newDead <- matrix(0, nrows, ncols, byrow = T)

  dailyVaccinated <- dailyExposed <- dailyInfected <- dailyRecovered <- dailyDead <- 0
#+end_src

#+name: recalculate the values within every cell of the raster and store them
#+begin_src R :noweb no-export
    <<Generating the I_tilda matrix>>

    nLiving <- valSusceptible + valVaccinated + valExposed + valInfected + valRecovered

    <<Some susceptible people are going to be newly vaccinated>>
    <<Some susceptible people who come in contact with nearby infected are going to be newly exposed>>
    <<Some exposed people are going to become newly infectious>>
    <<Some infectious people are going to either recover or die>>

    <<Store the next state of each cell>>
#+end_src

#+name: print allRasters and return the results
#+begin_src R :noweb no-export
  <<print statements №5>>

  <<print the individual timesteps for the Infected layer before merging into MP4>>

  summary[is.na(summary)] <- 0

  write_xlsx(summary, path = paste0("www/MP4/", inputISO, "_summary.xlsx"), col_names = T)

  return(summary)
#+end_src

#+name: write the daily incidences to the summary table and store the sum of compartments for writing at the beginning of the next iteration
#+begin_src R
    summary[t, 9]   <- dailyVaccinated
    summary[t, 10]  <- dailyExposed
    summary[t, 11]  <- dailyInfected
    summary[t, 12]  <- dailyRecovered
    summary[t, 13]  <- dailyDead

    sumS <- sum(values(Susceptible))
    sumV <- sum(values(Vaccinated))
    sumE <- sum(values(Exposed))
    sumI <- sum(values(Infected))
    sumR <- sum(values(Recovered))
    sumD <- sum(values(Dead))
#+end_src

** seed the simulation
#+name: seed the initial states from the provided seed data
#+begin_src R :noweb no-export
  #------------------------#
  # Initial seed locations #
  #------------------------#

  if (missing(seedFile)){
    seedFolder <- "seeddata/"         # .csv or .xlsx files may be stored in local seeddata/ folder
    seedData <<- read_excel(paste0(seedFolder, inputISO, "_InitialSeedData.csv"), header = T)
    seedData <<- read_excel(paste0(seedFolder, inputISO, "_InitialSeedData.xlsx"), 1, header = T)
  } else {
    seedData <<- read.csv(seedFile)
  }

  numLocations <- dim(seedData)[1]
  # print(numLocations)

  # Seed the initial infections equitably in a Moore Neighborhood of cells
  #seedRadius <- 0
  numCellsPerRegion <- (2*seedRadius + 1)^2
  for (ff in 1:numLocations)
  {
    # print(seedData)
    # print(paste("Seed location = ", seedData[ff,1]))
    row <- terra::rowFromY(stack$rasterStack, seedData[ff,2])
    col <- terra::colFromX(stack$rasterStack, seedData[ff,3])
    # print("row = ", row, "col = ", col)
    # print(Inhabitable[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)])
    # print(sum(Inhabitable[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)]))
    newVaccinatedPerCell <- seedData[ff,4]#/numCellsPerRegion    #round(seedData[ff,8]/numCellsPerRegion)
    newExpPerCell        <- seedData[ff,5]/numCellsPerRegion     #round(seedData[ff,5]/numCellsPerRegion)
    newInfPerCell        <- seedData[ff,6]/numCellsPerRegion     #round(seedData[ff,4]/numCellsPerRegion)
    newRecoveredPerCell  <- seedData[ff,7]#/numCellsPerRegion    #round(seedData[ff,6]/numCellsPerRegion)
    newDeadPerCell       <- seedData[ff,8]#/numCellsPerRegion    #round(seedData[ff,7]/numCellsPerRegion)
    # print(newVaccinatedPerCell)
    # print(newExpPerCell)
    # print(newInfPerCell)
    # print(newRecoveredPerCell)
    # print(newDeadPerCell)
    #Vaccinated[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] <- Vaccinated[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] + newVaccinatedPerCell
    Vaccinated[row,col] <- Vaccinated[row,col] + newVaccinatedPerCell
    Exposed[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] <- Exposed[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] + newExpPerCell
    Infected[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] <- Infected[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] + newInfPerCell
    #Recovered[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] <- Recovered[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] + newRecoveredPerCell
    Recovered[row, col] <- Recovered[row,col] + newRecoveredPerCell
    #Dead[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] <- Dead[(row-seedRadius):(row+seedRadius),(col-seedRadius):(col+seedRadius)] + newDeadPerCell
    Dead[row, col] <- Dead[row,col] + newDeadPerCell
    #print(Exposed)
    #print(paste("Susceptible = ", sum(values(Susceptible))))
  }
#+end_src

** Teardown before the next iteration of the simulation loop
#+name: Store the next state of each cell
#+begin_src R :noweb no-export
  #-----------------------------------#
  # Store the next state of each cell #
  #-----------------------------------#
  nextSusceptible <- valSusceptible - newExposed - newVaccinated
  nextVaccinated <- valVaccinated + newVaccinated
  nextExposed <- valExposed + newExposed - newInfected
  nextInfected <- valInfected + newInfected - newDead - newRecovered
  nextRecovered <- valRecovered + newRecovered
  nextDead <- valDead + newDead


  nextSusceptible[nLiving <= 0] <- 0
  nextVaccinated[nLiving <= 0] <- 0
  nextExposed[nLiving <= 0] <- 0
  nextInfected[nLiving <= 0] <- 0
  nextRecovered[nLiving <= 0] <- 0
  nextDead[nLiving <= 0] <- 0


  Susceptible <- nextSusceptible
  Vaccinated <- nextVaccinated
  Exposed <- nextExposed
  Infected <- nextInfected
  Recovered <- nextRecovered
  Dead <- nextDead

  Susceptible <- rast(Susceptible)
  Vaccinated <- rast(Vaccinated)
  Exposed <- rast(Exposed)
  Infected <- rast(Infected)
  Recovered <- rast(Recovered)
  Dead <- rast(Dead)

  ext(Susceptible) <- ext(Vaccinated) <- ext(Exposed) <- ext(Infected) <- ext(Recovered) <- ext(Dead) <- ext(stack$rasterStack)
  crs(Susceptible) <- crs(Vaccinated) <- crs(Exposed) <- crs(Infected) <- crs(Recovered) <- crs(Dead) <- crs(stack$rasterStack)

  <<print statements №4>>

  stack$rasterStack$Susceptible <- Susceptible
  stack$rasterStack$Vaccinated <- Vaccinated
  stack$rasterStack$Exposed <- Exposed
  stack$rasterStack$Infected <- Infected
  stack$rasterStack$Recovered <- Recovered
  stack$rasterStack$Dead <- Dead
#+end_src

* Recalculating the partial differential equations
This section recalculates the compartments composing an SVEIRD model.

** Generating the ~I_tilda~ matrix
Each iteration has a time-variant matrix of the probabilty of transmission.

\(\tilde{I}\) is referred to with a misspelled identifier (~I_tilda~) in the
original code, but we can do our best to ignore that.

The formula to calculate the matrix at each time is \(\tilde{I}_t =
\int\int_{\Omega_n} w(x,y,u,v) I(u,v,t) u^\prime v^\prime \).

#+name: Generating the I_tilda matrix
#+begin_src R
  #-------------------------------#
  # Generating the I_tilda matrix #
  #-------------------------------#
  I_tilda <- wtd_nbrs_sum(input_matrix = valInfected, radius = radius, lambda = lambda)
#+end_src

The new code for this is documented here, because it so so small. The
old code is documented separately in [[=distwtRaster.R= The Euclidian
distance weight matrix function]] because it is implemented in a
different file. It felt right to use a totally different heading to
document that file rather than document it herein.

#+begin_src R
  transmissionLikelihoods <-
    terra::focal(x = layers$Infected,
                 w = averageEuclideanDistance(lambda, if (aggregationFactor > 1) aggregationFactor),
                 na.policy = "omit",
                 fillvalue = 0,
                 fun = "sum",
                 na.rm = TRUE)

  uniqueInfectionLikelihoods <- length(unique(as.vector(transmissionLikelihoods)))
  if (is.nan(sums[, "Infected"]))
    warning("The result of (global) sum total of the Infected compartment is \
  NaN according to terra, so the check that the number of unique infection \
  likelihoods is greater than one is being skipped this iteration. See issue #13.")
  if (all(!is.nan(sums[, "Infected"]),
          as.numeric(sums[, "Infected"]) >= 0,
          !(uniqueInfectionLikelihoods > 1)))
    stop("The number of unique likelihoods of transmission is not more than \
  one, indicating an issue generating the transmissionLikelihoods matrix.")
#+end_src

Checks were written to ensure that a further check was only run under certain
conditions. The pre-flight (pre-check) check I wrote was the solution to
[[https://github.com/KrishnamurthyLab/spatialEpisim.foundation/issues/13][issue №13. More information is available within that issue]] and in the issue
storyline.

[[https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/how-focal-statistics-works.htm][ArcGIS has a /perfect/ article examining focal statistics (including /literal
edge cases/) in their online tool reference.]] /terra/ performs calculations using
user-defined or built-in functions similarly, and this reference should be
consulted.

It's unlikely that the original code handled the edge cases /properly/, so the
use of ~terra::focal~ is a boon in more than one way:

1. it's much more readable,
2. it's one less function to worry about, and
3. it handles edge cases!

The method to compare these will not be very complex, just a simple test raster
and comparing the outputs visually and numerically. The old code cannot handle
non-matrix classed objects as ~input_matrix~, so this is manually dealt with in
the comparison code.

I learned of a bug in the new code! When calling a function, if you have a NULL
expression like this ~averageEuclideanDistance(lambda, if (aggregationFactor
> 1) aggregationFactor)~ then the function recieves that invisible NULL that is
returned when an if statement does not proceed (i.e., ~is.null(if(FALSE) FALSE)~
returns TRUE. While it's aesthetically pleasing to pass arguments this way, it
does not result in the function call using the default argument for
~aggregationFactor~. A fix is applied in
[[https://github.com/KrishnamurthyLab/spatialEpisim.foundation/commit/6a5305c659b033abdd4c7ccbbbd11543f095d8f2][6a5305c]].

#+begin_src R :noweb no-export :session *foundation* :export both :results file link
  v <- vect(system.file("ex/lux.shp", package="terra"))
  r <- rast(system.file("ex/elev.tif", package="terra"))
  r[45:50, 45:50] <- NA

  valInfected <- as.matrix(r, wide = TRUE)
  lambda <- 15 # km/day, on average
  radius <- 3 # cells? kilometers? The old code doesn't say anything!
  aggregationFactor <- 0 # Luxembourg is tiny, so we don't aggregate!

  ## Old code, generating "I_tilde"
  <<source dependencies>>
  <<Generating the I_tilda matrix>>

  ## New code
  I_tilde <- terra::focal(x = r,
                          w = averageEuclideanDistance(radius),
                          na.policy = "omit",
                          fillvalue = 0,
                          fun = "sum",
                          na.rm = TRUE)

  I_tilda <- rast(I_tilda)
  ext(I_tilda) <- ext(I_tilde)
  crs(I_tilda) <- crs(I_tilde)

  plotLayers <- I_tilde
  add(plotLayers) <- I_tilda
  add(plotLayers) <- r
  panel(plotLayers)
  filepath <- "R/infectionLikelihoodsComparisonTwo.png"
  savePlot(filepath)
  basename(filepath)
#+end_src

#+RESULTS:
[[file:infectionLikelihoodsComparisonTwo.png]]

#+DOWNLOADED: file:///home/bryce/Documents/src/r/spatialEpisim.stable/R/infectionLikelihoodsComparisonTwo.png @ 2024-10-02 21:59:06
[[file:Simulation_(optionally_with_data_assimilation)_cont./2024-10-02_21-59-06_infectionLikelihoodsComparisonTwo.png]]

In the top-right of this plot the old code's plot is shown. This panel plot
should only be viewed for the shape of the data, not the value. The shape of the
data in the top-right is shrunken, where the infection likelihoods near edges of
the map are reeled back, and a purposefully created hole in the map is enlarged
similarly.

The values in the map produced using a focal sum are a good bit lower than the
values produced using the old code, after changing the
~averageEuclideanDistance(lambda = lambda)~ to ~averageEuclideanDistance(lambda
= radius)~, which results in a weights matrix used by the calling function the
same dimension as the ~weight_matrix~ used by the old code. Using ~lambda =
lambda~ results in a weight matrix used by ~terra::focal~ which has much greater
dimensions.

The ~weight_matrix~ produced within the ~wtd_nbrs_sum(radius = 3, lambda = 15)~
and the ~averageEuclideanDistance(lambda = 3)~ (I'm aware of the difference in
argument names, I need to adjust the documentation and formal argument/parameter
names) are similar, but the new is much smoother and more accurate, in my
opinion. The old ~weight-matrix~ is on the left, and the new matrix
(~averageEuclideanDistance(3)~) is on the right.

#+DOWNLOADED: file:///home/bryce/Documents/src/r/spatialEpisim.stable/R/comparisonOfEuclideanDistanceWeightings.png @ 2024-10-02 21:43:16
[[file:Simulation_(optionally_with_data_assimilation)_cont./2024-10-02_21-43-16_comparisonOfEuclideanDistanceWeightings.png]]

The focal sum function in terra is indispensible, and the average Euclidean
distance function that I wrote is much smoother, producing values which don't
change as abruptly in value. Both functions could be offered in Shiny, with the
user offered a preview of each function's results. The old code should not be
used otherwise, however.

** Vaccination
#+name: Some susceptible people are going to be newly vaccinated
#+begin_src R
  #--------------------------------------------------------------------#
  # Some susceptible people are going to be newly vaccinated           #
  #--------------------------------------------------------------------#
  newVaccinated <- alpha*valSusceptible
  newVaccinated[valSusceptible < 1] <- 0

  dailyVaccinated <- sum(newVaccinated)
#+end_src

** Exposure (infection)
#+name: Some susceptible people who come in contact with nearby infected are going to be newly exposed
#+begin_src R
  #--------------------------------------------------------------------#
  # Some susceptible people who come in contact with nearby infected   #
  # are going to be newly exposed                                      #
  #--------------------------------------------------------------------#
  pSusceptible <- valSusceptible/nLiving
  pSusceptible[is.nan(pSusceptible)] <- 0

  if(deterministic) {
    newExposed <- beta*pSusceptible*I_tilda
  } else {
    rpois(1, beta*pSusceptible*I_tilda)
  }
  newExposed[valSusceptible < 1] <- 0
  newExposed[I_tilda < 1] <- 0

  dailyExposed <- sum(newExposed)
  cumExposed <- cumExposed + sum(newExposed)
#+end_src

** Infectiousness
#+name: Some exposed people are going to become newly infectious
#+begin_src R
  #----------------------------------------------------------#
  # Some exposed people are going to become newly infectious #
  #----------------------------------------------------------#
  newInfected <- gamma*valExposed
  newInfected[valExposed < 1] <- 0

  dailyInfected <- sum(newInfected)
  cumInfected   <- cumInfected + sum(newInfected)
#+end_src

** Recovery and death
#+name: Some infectious people are going to either recover or die
#+begin_src R
  #-----------------------------------------------------------#
  # Some infectious people are going to either recover or die #
  #-----------------------------------------------------------#
  newRecovered <- sigma*valInfected
  newRecovered[valInfected < 1] <- 0

  dailyRecovered <- sum(newRecovered)
  cumRecovered <- cumRecovered + sum(newRecovered)

  newDead <- delta*valInfected
  newDead[valInfected < 1] <- 0

  dailyDead <- sum(newDead)
  cumDead <- cumDead + sum(newDead)
#+end_src

* Bayesian data assimilation
When the simulation has BDA enabled a necessary amount of setup occurs before
the main loop; within the main loop of the function body the Bayesian data
assimilation actually occurs (at specified times).

#+begin_comment
Bayesian data assimilation was not fully implemented in the original code (the
code before I joined the project). It did not properly handle its input
arguments, as when two states of observations were provided---Infection and
Death---only Infection was handled; if a second state was observed and uploaded
the application would crash (if I recall).
#+end_comment

** Setup the data to be read for BDA, and create time-invariant LIO matrix

#+name: setup to perform when using Bayesian data assimilation
#+begin_src R :noweb no-export
    if (DA == T)
    {
      #-------------------------------------------#
      # Import the Ebola Incidence and Death Data #
      #-------------------------------------------#

      incidence_data <- read_excel(dataI)
      #death_data <- read_excel(dataD)

      print(paste("Dimension of Incidence Matrix: ", dim(incidence_data)[1], dim(incidence_data)[2]))

      #print(paste("Dimension of Death Matrix: ", dim(death_data)[1], dim(death_data)[2]))

      ## DONT change this here, change it in spatialEpisim.foundation is needed,
      ## then copy over the function defintion here.
      <<linear interpolation operator function backported from spatialEpisim.foundation>>

      states_observable <- 1
      healthZoneCoordinates <- openDataFile(sitRepData)
      stopifnot(hasName(healthZoneCoordinates, "HealthZone"))
      stopifnot(hasName(healthZoneCoordinates, "Latitude"))
      stopifnot(hasName(healthZoneCoordinates, "Longitude"))
      Hmat <- linearInterpolationOperator(terra::rast(stack$rasterStack), healthZoneCoordinates)
      nHealthZones <- nrow(healthZoneCoordinates)

      #------------------#
      # Read in Q matrix #
      #------------------#
      source("R/Q_matrix.R")

      QMat <- genQ(nrows, ncols, varCovarFunc, QVar, QCorrLength, nbhd, states_observable =  states_observable) #states_observable = 2

      Q <- QMat$Q
      # plot(Q[1:101,1])
      # plot(Q[1,1:101])
      # print(diag(Q)[1:200])
      # print(det(Q))

      # print(paste("Dimension of the Model Error Covariance Matrix: ", dim(Q)[1], dim(Q)[2]))

      QFull <- QMat$QFull
      # print(det(QFull))
      # print(paste("Dimension of the Block Diagonal Model Error Covariance Matrix: ", dim(QFull)[1], dim(QFull)[2]))

      QHt <- QFull%*%t(Hmat)

      HQHt <- Hmat%*%QHt

      #print(HQHt)
      #print(paste("Dimension of HQHt Matrix: ", dim(HQHt)[1], dim(HQHt)[2]))

      #print(HQHt[1:8, 1:8])

      ## HQHt is a square-symmetric matrix
        print(rowSums(HQHt))
        print(colSums(HQHt))
      # table(rowSums(HQHt))
      # table(colSums(HQHt))
        print(diag(HQHt))

        print(paste("det(HQHt) is:", det(HQHt)))

      # eigen(HQHt)$values
        print(sum(eigen(HQHt)$values)) # Sum of eigenvalues is equal to q

      #----------------------#
      # Plot the HQHt matrix #
      #----------------------#

      # source("R/plotHQHt.R")
      # plotHQHt(HQHt)
    }
#+end_src

*** Linear interpolation
The operator matrix for linear interpolation was incorrectly implemented in the
original code. This correctly implemented function is backported from the
/spatialEpisim.foundation/ package to provide the "stable" version of the Shiny
application's simulation core a correction/bug-fix.

#+name: linear interpolation operator function backported from spatialEpisim.foundation
#+begin_src R :noweb no-export
  linearInterpolationOperator <- function(layers,
                                          healthZoneCoordinates,
                                          neighbourhood.order = 2,
                                          compartmentsReported = 1) {
    stopifnot(neighbourhood.order %in% c(0, 1, 2))
    if (neighbourhood.order == 2)
      stopifnot(terra::ncell(layers) >= 5 && terra::nrow(layers) >= 5) # required for 2nd order
    stopifnot(compartmentsReported %in% 1:2)

    queensNeighbours <- function(order, cell, ncols) {
      stopifnot(order %in% 1:2)

      if (order == 1) {
        neighbouringCells <-
          c((cell - ncols - 1) : (cell - ncols + 1),
            cell - 1 , cell + 1,
            (cell + ncols - 1) : (cell + ncols + 1))
        stopifnot(length(neighbouringCells) == 8)
      } else if (order == 2) {
        neighbouringCells <-
          c((cell - ncols * 2 - 2) : (cell - ncols * 2 + 2),
            cell - ncols - 2 , cell - ncols + 2,
            cell - 2 , cell + 2,
            cell + ncols - 2 , cell + ncols + 2,
            (cell + ncols * 2 - 2) : (cell + ncols * 2 + 2))
        stopifnot(length(neighbouringCells) == 16)
      }

      neighbouringCells
    }

    extend.length <- 5
    layers <- terra::extend(layers, extend.length)

    ## NOTE: cells contains the index into the rasters in layers (when converted
    ## to a matrix). Extract coordinates as cbind(lon, lat); it's stored as
    ## cbind(lat, lon).
    cells <- terra::cellFromXY(layers, terra::as.matrix(healthZoneCoordinates[, 3:2]))

    if (any(duplicated(cells))) {
      overaggregatedHealthZones <- tibble::tibble("Health Zone" = healthZoneCoordinates[, 1], Cell = cells) %>%
        dplyr::group_by(Cell) %>%
        dplyr::filter(dplyr::n() != 1)

      warning(sprintf("[Linear interpolation operator] Raster aggregation factor is too high to differentiate between two (or more) health zones (they correspond to the same grid cell).\n%s",
                      ## Based on the helpful answer by Richie Cotton on SO:
                      ## https://stackoverflow.com/a/26083626/14211497, which the following is
                      ## based on.
                      paste(capture.output(print(overaggregatedHealthZones)), collapse = "\n")))
    }
    if (any(is.na(cells)))
      warning("Ignoring NAs in [cells] object corresponding to coordinates out of bounds of [layers] SpatRaster.")

    cells <- cells[!is.na(cells)]

    ## NOTE: preallocate the linear forward interpolation matrix, with
    ## dimensions q * p (health zones by cells in the SpatRaster).
    H <- base::matrix(0, nrow(healthZoneCoordinates), terra::ncell(layers))

    ## NOTE: these are the weightings used for the chess queen zeroth, first,
    ## and second order neighbours. The zeroth order neighbor is the position of
    ## the queen itself.
    neighbour.weights <-
      switch(neighbourhood.order + 1, # the first of ... applies to zero, etc.
             1,
             c(2, 1) * 0.1,
             c(3, 2, 1) * 35^-1)

    for (index in seq_along(cells)) {
      H[index, cells[index]] <- neighbour.weights[1]

      if (neighbourhood.order != 0) {
        neighbour.1st <- queensNeighbours(1, cells[index], terra::ncol(layers))
        H[index, neighbour.1st] <- neighbour.weights[2]
      }

      if (neighbourhood.order == 2) {
        neighbour.2nd <- queensNeighbours(2, cells[index], terra::ncol(layers))
        if(anyDuplicated(c(neighbour.1st, neighbour.2nd)) > 0)
          simpleError("Duplicate cell indices among neighbours of multiple localities.")
        H[index, neighbour.2nd] <- neighbour.weights[3]
      }
    }

    ## TODO: move the following NOTE to a better place than here; perhaps to the
    ## function documentation details. This should be tested using automatic
    ## testing with various input values. NOTE: this corresponds to the
    ## hand-written note I made after discussionwith Ashok. He told me that the
    ## sum of all cells needs to be equivalent to one; the sum of all cells is
    ## per-health zone, ergo the first condition checks that the sum of the entire
    ## matrix (with nrow := health zones) is the same as the number of health
    ## zones (because each should sum to one). NOTE: each row corresponds to one
    ## of the neighourhoods pictures in the plots "ashok.png" or "me.png".
    stopifnot(dplyr::near(sum(H), nrow(healthZoneCoordinates)))
    stopifnot(dplyr::near(sum(matrix(H[1, ],
                                     ncol = ncol(layers),
                                     byrow = TRUE)),
                          1))

    ## NOTE: the extended areas of the matrix are now dropped to return the matrix
    ## to the expected size for the input.
    H <-
      apply(X = H,
            MARGIN = 1, # apply the function to rows
            FUN =
              function(row) {
                m <- matrix(row, byrow = TRUE, ncol = ncol(layers))
                m[(extend.length + 1):(base::nrow(m) - extend.length),
                (extend.length + 1):(base::ncol(m) - extend.length)] %>%
                  Matrix::t() %>% # row-major order (byrow)
                  as.vector()
              }) %>% Matrix::t() # rows should be health zones

    if (compartmentsReported == 2) H <- as.matrix(Matrix::bdiag(H, H))

    stopifnot(sum(.rowSums(H, m = nrow(H), n = ncol(H))) == (compartmentsReported * nrow(healthZoneCoordinates)))

    return(H)
  }
#+end_src
** Assimilate data
#+name: Bayesian data assimilation
#+begin_src R :noweb no-export
      #setwd(outputDir) # Change working directory to output folder

      if (DA == T)
      {                     # DA T/F
        #NewoutputDir <- paste(outputDir, "/DA", sep="") # The directory for output files
        #if (!(file.exists(NewoutputDir))){
          #dir.create("DA") # Folder to store output files

        #setwd(NewoutputDir) # Change working directory to output folder

        if (t %% 7 == 0)
        {                   # elapsed week
          datarow <- datarow + 1

          if (datarow < 76)
          {                 # datarow cap
            #----------------------------------------#
            # Write forecast (prior) state to matrix #
            #----------------------------------------#

            # print(paste("Xf is printed on day", t))

            #---------------------#),
            # OSI: forecast state #
            #---------------------#
            # We track the  "Infectious" and "Dead" epidemic compartments

            print('Running Data Assimilation...')

            preDASusceptible <- Susceptible
            preDAVaccinated <- Vaccinated
            preDAExposed <- Exposed
            preDAInfected <- Infected
            preDARecovered <- Recovered
            preDADead <- Dead

            rat <- sum(terra::as.matrix(Exposed, wide = TRUE))/(sum(terra::as.matrix(Infected, wide = TRUE))+0.000000001)

            Infected <- terra::as.matrix(Infected, wide = TRUE) # default is byrow = F

            # print(dim(Infected))
            # Dead <- as.matrix(Dead, byrow = T) # default is byrow = F

            Xf.OSI <- t(t(as.vector(t(Infected))))

            # Xf.OSI <- t(cbind(t(as.vector(Infected)), t(as.vector(Dead))))

            # print(paste("Dimension of the state vector:")); print(dim(Xf.OSI))

             #print(sum(Xf.OSI))
            # table(Xf.OSI)

            HXf <- Hmat%*%Xf.OSI
            #print(HXf)
            #print(dim(HXf))
            #print(sum(HXf))

            #----------------------------------------------#
            # Importing DRC Ebola Incidence and Death Data #
            #----------------------------------------------#

            incidence <- as.vector(incidence_data[datarow, 1:nHealthZones+2]) # Pick a row every 7 days, select third column through to the last column
            #death <- as.vector(death_data[datarow, 1:nHealthZones+2])         # Pick a row every 7 days, select third column through to the last column

            # if (datarow > 1)
            # {                 # datarow > 1
            #    prevWHOIncidence <- sum(as.vector(incidence_data[1:(datarow-1), 3:nHealthZones+2]))
            #    currWHOIncidence <- sum(as.vector(incidence_data[1:datarow, 3:nHealthZones+2]))
            #
            #    currSIMIncidence <-
            #    prevSIMIncidence <-
            #
            #    slopeWHO <- (currWHOIncidence - prevWHOIncidence)/nDaysPerUnit
            #    slopeSIM <- (currSIMIncidence - prevSIMIncidence)/nDaysPerUnit
            #
            #    phi <- slopeWHO/slopeSIM
            #
            #   #beta = phi*beta
            #
            # }                 # datarow > 1

            #Dvector <- t(cbind(t(incidence), t(death)))
            Dvector <- incidence

            # print(Dvector)

            #-------------------------------------#
            # Measurement error covariance matrix #
            #-------------------------------------#

            # sum(Dvector < 1)
            Dvector_revised <- ifelse(Dvector < 1, psiDiag, Dvector) # If a diagonal entry is zero change it to 0.1/1.
            # sum(Dvector_revised < 1)

            q <- nHealthZones*states_observable

            M <- diag(as.vector(Dvector_revised))

            #M <- M*exp(-t/10)

            # print(M)

            # print(det(HQHt+M))

            # library(MASS)
            # write.matrix(M, file = 'mes_err.csv')

            # print(M) # check if D vector needs to be really revised

            # levelplot(M, col.regions= colorRampPalette(c("white", "red", "blue")))
            # table(M)
            # diag(M)
            # det(M)

            #---------------------#
            # Optimal Kalman Gain #
            #---------------------#

            # sum(QHt < 0)
            # sum(HQHt < 0)

            # levelplot(as.matrix(HQHt), col.regions= colorRampPalette(c("white", "red", "blue")))

            # diag(HQHt)
            # det(HQHt)
            # eigen(HQHt)$values # HQHt isn't positive definite since all of its eigenvalues are not strictly positive.
            # sum(eigen(HQHt)$values)
            #
            # log10(max(eigen(HQHt)$values)/min(eigen(HQHt)$values))
            #
            # det(solve(HQHt))
            # eigen(solve(HQHt))$values # Inverse of HQHt is also not positive definite since all of its eigenvalues are not strictly positive.
            # # sum(eigen(solve(HQHt))$values)

            # The gain matrix, Ke.OSI, determines how the observational data are to be assimilated
            Ke.OSI <- QHt%*%solve(HQHt + M)

            # print(dim(Ke.OSI))

            #write.matrix(Ke.OSI, file = 'Kal_Gain.csv') #solve((HQHt + M), t(QHt))

            #print(paste("Dimension of the Kalman Gain Matrix:")); print(dim(Ke.OSI))

            # Can the Kalman gain matrix have negative values? Yes.
            # Can the innovation or measurement residual have negative values? Yes.

            #------------------------------------#
            # Innovation or measurement residual #
            #------------------------------------#
            # HXf <- t(t(as.numeric(Dvector)))
            # print(dim(QFull))
            # print(dim(Hmat))
            # print(dim(t(Hmat)))
            cbind(t(t(as.numeric(Dvector))), HXf, t(t(as.numeric(Dvector))) - HXf)

            Y <- t(t(as.numeric(Dvector))) - HXf

            print(sum(Y))
            print(sum(Ke.OSI%*%Y))

            #---------------------------------#
            # OSI update step: analysis state #
            #---------------------------------#

            which(Xf.OSI > 0)

            #sum(Ke.OSI%*%Y < 0)
            length(which(Ke.OSI%*%Y < 0))
            length(which(Ke.OSI%*%Y > 0))
            length(which(Ke.OSI%*%Y == 0))

            Xa.OSI <- Xf.OSI + Ke.OSI%*%Y

            #print(length(Xa.OSI[Xa.OSI < 0]))

            #print(summary(Xa.OSI[Xa.OSI < 0]))

            # print(which.max(Xa.OSI))

            Xa.OSI[Xa.OSI < 0] <- 0 # This will set all negative values to zero. TBW convinced me.

            #print(length(Xa.OSI[Xa.OSI < 0]))

            # Xa.OSI <- abs(Xf.OSI + Ke.OSI%*%Y)

            # max(Ke.OSI%*%Y)
            # min(Ke.OSI%*%Y)
            #
            # sum(round(Ke.OSI%*%Y))
            #
            # print(sum(Xa.OSI))
            # print(tail(sort(Xa.OSI), 50))
            # print(sum(Xf.OSI))

            ###########################

            # sum(Xf.OSI < 0)         # Number of negative values in Xf.OSI.
            #
            # sum(QHt < 0)        # Number of negative values in QHt.
            #
            # sum(HQHt < 0)           # Number of negative values in HQHt.
            #
            # sum(Y < 0)              # Number of negative values in Y.
            #
            # sum(Ke.OSI < 0)         # Number of negative values in Ke.OSI.
            #
            # sum(Ke.OSI%*%Y < 0)     # Number of negative values in Ke.OSI*Y.
            #
            # sum(Xa.OSI < 0)         # Number of negative values in Xa.OSI.

            ###########################

            # HXf <- Hmat%*%Xf.OSI
            # print(dim(HXf))
            # print(sum(HXf))
            #
            # HXa <- Hmat%*%Xa.OSI
            # print(dim(HXa))
            # print(sum(HXa))

            # cbind(HXf, round(HXa), HXa)

            # print(cbind(Dvector, Hmat%*%Xf.OSI, Y, round(Hmat%*%Xa.OSI)))

            # NOTE: when restacking make sure byrow = T.

            I <- matrix(Xa.OSI[1:p], nrow = nrows, ncol = ncols, byrow = T) # AK

            # print('max index is')
            #
            # print(which(I == max(I), arr.ind=TRUE))

            # write.matrix(I, file = 'infected.csv')

            # I[I < 1] <- 0 # Prevent tiny values for the number of infectious

            # D <- matrix(Xa.OSI[(p+1):(2*p)], nrow = nrows, ncol = ncols, byrow = T)
            # print(sum(D))

            #D[D < 1] <- 0 # Prevent tiny values for the number of dead

            dim(Xa.OSI); dim(I);
            # dim(D);
            min(I);
            #min(D);
            max(I);
            #max(D)

            # For all uninhabitable cells set the number of infected and dead = 0. THIS IS VERY CRITICAL!!!

            # for(i in 1:nrows)
            # {                 # nrows
            #   for(j in 1:ncols)
            #   {               # ncols
            #     if (stack$rasterStack$Inhabitable[i,j] == 0)
            #     {             # Inhabitable
            #       #I[i,j] <- D[i,j] <- 0
            #       I[i,j] <- 0
            #     }
            #   }
            # }
            # I[stack$rasterStack$Inhabitable[stack$rasterStack$Inhabitable == 0]] <- 0
            I[valInhabitable == 0] <- 0

            values(stack$rasterStack$Infected) <- I
            # values(stack$rasterStack$Dead) <- D
            Infected <- stack$rasterStack$Infected
            # Dead <- stack$rasterStack$Dead
            cumInfected <- cumInfected + sum(I - terra::as.matrix(preDAInfected, wide = TRUE))

            # cumDead <- cumDead + sum(D - as.matrix(preDADead))
            # print(sum(D - as.matrix(preDADead)))

            # deadDiff <- preDADead - Dead
            # Recovered <- preDARecovered + deadDiff
              Exposed <- rat*Infected
            # exposedDiff <- preDAExposed - Exposed
            # Susceptible <- preDASusceptible + exposedDiff

            # stack$rasterStack$Recovered <- Recovered
              stack$rasterStack$Exposed <- Exposed
            # stack$rasterStack$Susceptible <- Susceptible

            # print('max index is'); print(which.max(Infected))
           } # datarow cap
          } # If t is divisible by 7
        # elapsed week
      }
#+end_src

* Miscellany
This section is a few gatherings of print statements which are distracting
otherwise, and broken examples from the original code.

** MP4-related code
#+name: unlink, delete, and recreate the MP4 output directory
#+begin_src R
  unlink("www/MP4", recursive = TRUE, force = TRUE) # Delete the MP4
  dir.create("www/MP4")               # Create empty MP4 folder before running new simulation
  dir.create("www/MP4/paper")         # Create paper folder before for plots without labels
#+end_src

After the actual simulation runs some of the results are printed to raster files
and then merged into an MP4 video file for viewing.

#+name: print the individual timesteps for the Infected layer before merging into MP4
#+begin_src R :noweb no-export
    # Print a PNG for the infected variable
    rasterLayer <- "Infected"
    #print(allRasters[[1]]$rasterStack[[rasterLayer]])
    maxRasterLayerVal <- 0

    for (t in 1:timestep){
      tempMax <- minmax(allRasters[[t]]$rasterStack[[rasterLayer]])
      maxRasterLayerVal <- max(maxRasterLayerVal, tempMax)
    }

    ramp <- c('#FFFFFF', '#D0D8FB', '#BAC5F7', '#8FA1F1', '#617AEC', '#0027E0', '#1965F0', '#0C81F8', '#18AFFF', '#31BEFF', '#43CAFF', '#60E1F0', '#69EBE1', '#7BEBC8', '#8AECAE', '#ACF5A8', '#CDFFA2', '#DFF58D', '#F0EC78', '#F7D767', '#FFBD56', '#FFA044', '#EE4F4D')
    pal <- colorRampPalette(ramp)

    for (t in 1:timestep){
      fname = paste0("MP4/", inputISO, "_", rasterLayer, "_", sprintf("%04d", t), ".png")
      printStackLayer(rasterStack = allRasters[[t]]$rasterStack,
                      rasterLayer = rasterLayer,
                      directOutput = directOutput,
                      Level1Identifier = stack$Level1Identifier,
                      selectedCountry = selectedCountry,
                      rasterAgg = rasterAgg,
                      fname = fname,
                      maxVal = maxRasterLayerVal,
                      includeLabels = T,
                      isCropped)

      # fname = paste0("MP4/", "paper/", inputISO, "_", rasterLayer, "_", sprintf("%04d", t), "_paper", ".png")
      # printStackLayer(rasterStack = allRasters[[t]]$rasterStack, rasterLayer = rasterLayer, directOutput = directOutput, Level1Identifier = stack$Level1Identifier, selectedCountry, rasterAgg = rasterAgg, fname = fname, maxVal = maxRasterLayerVal, includeLabels = F)
    }

    # MERGE THE PNGs TO A GET AN MP4 VIDEO
    setwd("www/MP4")
    videoDuration <- 15 # in seconds
    av::av_encode_video(list.files(pattern = ".png"),
                        framerate = timestep/videoDuration,
                        output = paste0(rasterLayer, "_MP4.mp4"))
    setwd("./../..")
#+end_src

** Print statements
There are many paragraphs and sections of print statements, commented and not
commented, throughout the olde code. They are gathered here so that focus on the
actual simulation can be achieved when reading the code.

#+name: print statements №1
#+begin_src R
  # print(Level1Identifier$NAME_1)  # List of states/provinces/regions

  # plot(Level1Raster)
  # plot(Level1Identifier, add = TRUE)
  #
  # print(Susceptible);  print(Vaccinated); print(Exposed); print(Infected); print(Recovered); print(Dead)
  #
  # dim(Susceptible); dim(Vaccinated); dim(Exposed); dim(Infected); dim(Recovered); dim(Dead); dim(Inhabitable); dim(Level1Raster)
  #
  # print(table(values(Inhabitable)))
#+end_src

#+name: print statements №1.5
#+begin_src R
  ramp <- c('#FFFFFF', '#D0D8FB', '#BAC5F7', '#8FA1F1', '#617AEC', '#0027E0', '#1965F0', '#0C81F8', '#18AFFF', '#31BEFF', '#43CAFF', '#60E1F0', '#69EBE1', '#7BEBC8', '#8AECAE', '#ACF5A8', '#CDFFA2', '#DFF58D', '#F0EC78', '#F7D767', '#FFBD56', '#FFA044', '#EE4F4D')
  pal <- colorRampPalette(ramp)
#+end_src

#+name: print statements №2
#+begin_src R
  # print("new----------------")
  # print(valVaccinated)
  # print("-------------------")

  #par(mfrow = c(1, 2))

  # plot(Infected, col = pal(8)[-2], axes = T, cex.main = 1,
  #      main = "Location of Initial Infections",
  #      xlab = expression(bold("Longitude")), ylab = expression(bold("Latitude")),
  #      legend = TRUE, horizontal = TRUE, mar=c(8.5, 3.5, 2.5, 2.5))
  #
  # plot(Level1Identifier, add = TRUE)
  #
  # plot(Dead, col = pal(8)[-2], axes = T, cex.main = 1,
  #      main = "Location of Initial Deaths",
  #      xlab = expression(bold("Longitude")), ylab = expression(bold("Latitude")),
  #      legend = TRUE, horizontal = TRUE, mar=c(8.5, 3.5, 2.5, 2.5))
  #
  # plot(Level1Identifier, add = TRUE)
  #
  # plot(log10(Susceptible), col = pal(8)[-2], axes = T, cex.main = 1, main = "Susceptible", legend=TRUE, mar=c(8.5, 3.5, 2.5, 2.5))
  # plot(Level1Identifier, add = TRUE)
  #
  # plot(Inhabitable, col = pal(8)[-2], axes = T, cex.main = 1, main = "Inhabitable Cells", legend=TRUE, mar=c(8.5, 3.5, 2.5, 2.5))
  # plot(Level1Identifier, add = TRUE)

  # writeRaster(Infected, "seed.tif", overwrite = TRUE)
#+end_src

#+name: print statements №3
#+begin_src R
  # print(propVaccinated)
  # print(propExposed)
  # print(propInfected)
  # print(propRecovered)
  # print(propDead)

  print(paste("Susceptible Count before removing initial seed values: ", sum(values(Susceptible))))
  # print(values(Susceptible))
#+end_src

#+name: print statements №4
#+begin_src R
  # ramp <- c('#FFFFFF', '#D0D8FB', '#BAC5F7', '#8FA1F1', '#617AEC', '#0027E0', '#1965F0', '#0C81F8', '#18AFFF', '#31BEFF', '#43CAFF', '#60E1F0', '#69EBE1', '#7BEBC8', '#8AECAE', '#ACF5A8', '#CDFFA2', '#DFF58D', '#F0EC78', '#F7D767', '#FFBD56', '#FFA044', '#EE4F4D')
  # pal <- colorRampPalette(ramp)
  #
  # plot(Infected, col = pal(8)[-2], axes = T, cex.main = 1,
  #      main = "Location of Infections after iteration t",
  #      xlab = expression(bold("Longitude")), ylab = expression(bold("Latitude")),
  #      legend = TRUE, horizontal = TRUE, mar=c(8.5, 3.5, 2.5, 2.5))
  #
  # plot(Level1Identifier, add = TRUE)
  # print(Infected)
  #
  # writeRaster(Infected, file = "infectedRaster.tif", overwrite = TRUE)
#+end_src

#+name: print statements №5
#+begin_src R
  # save(stack$rasterStack[["Infected"]], file = "infectedRaster.RData")

  # plot(allRasters[[t]]$rasterStack[["Infected"]], col = pal(8)[-2], axes = T, cex.main = 1, main = "Location of Initial Infections", plg = list(title = expression(bold("Persons")), title.cex = 1, horiz=TRUE, x.intersp=0.6, inset=c(0, -0.2), cex=1.15), pax = list(cex.axis=1.15), legend=TRUE, mar=c(8.5, 3.5, 2.5, 2.5), add = F)
  #
  # plot(Level1Identifier, add = TRUE)
#+end_src

** Broken examples
The examples didn't work. The documentation was outdated.

#+name: examples
#+begin_src R
  #--------------#
  # Example Call #
  #--------------#

  # Arguments

  # model, startDate, selectedCountry, directOutput, rasterAgg,
  # alpha, beta, gamma, sigma, delta, radius, lambda, timestep, seedFile,
  # deterministic, isCropped, level1Names, DA = F,
  # sitRepData, dataI, dataD, varCovarFunc, QVar, QCorrLength

  # model <- "SVEIRD" # "SEIRD"
  # startDate <- "2018-08-05" # today()
  # selectedCountry <- "Democratic Republic of Congo"
  # directOutput <- F
  # rasterAgg <- 10

  #t <- 1

  #------------#
  # Parameters #
  #------------#

  # alpha <- 0.000035  # Daily fraction that move out of the susceptible compartment to the vaccinated compartment
  # beta  <- 0.007 # 0.006     # Daily fraction that move out of the susceptible compartment to the exposed compartment
  # gamma <- 1/7  # 0.1428571      # Daily fraction that move out of the exposed compartment to the infectious compartment **** Gamma has to remain the same for all scenarios
  # sigma <- 1/36 # 0.02777778     # Daily fraction that move out of the infectious compartment to the recovered compartment
  # delta <- 2/36 # 0.05555556     # Daily fraction that move out of the infectious compartment to the dead compartment

  # radius <- 1 # apply formula as discussed
  # lambda <- 15
  # timestep <- 564
  #
  # seedFile <- "seeddata/COD_InitialSeedData.csv"
  # seedRadius <- 1
  #
  # deterministic <- T
  # isCropped <- T
  # level1Names <- c("Ituri", "Nord-Kivu")
  #
  # DA <- T # F #
  #
  # sitRepData <- "observeddata/Ebola_Health_Zones_LatLon.csv"
  # dataI <- "observeddata/Ebola_Incidence_Data.xlsx"
  # dataD <- "observeddata/Ebola_Death_Data.xlsx"
  #
  # varCovarFunc <- "DBD" # "Balgovind"
  # QVar <- 0.55
  # QCorrLength <- 0.675
  # nbhd <- 3
  # psiDiag <- 0.001

  #------------#
  # DA is TRUE #
  #------------#

  #SpatialCompartmentalModelWithDA(model, startDate, selectedCountry, directOutput, rasterAgg, alpha, beta, gamma, sigma = 1/21, delta = 2/21, radius, lambda, timestep, seedFile = "seeddata/COD_InitialSeedData.csv", seedRadius, deterministic, isCropped, level1Names, DA = F, "observeddata/Ebola_Health_Zones_LatLon.csv", "observeddata/Ebola_Incidence_Data.xlsx", "observeddata/Ebola_Death_Data.xlsx", varCovarFunc = "DBD", QVar, QCorrLength, nbhd, psiDiag)

  #-------------#
  # DA is FALSE #
  #-------------#

  #SpatialCompartmentalModelWithDA(model, startDate, selectedCountry = "Czech Republic", directOutput, rasterAgg, alpha = 0.0015, beta = 0.05, gamma = 0.16, sigma = 0.065, delta = 0.002, radius, lambda, timestep = 120, seedFile = "seeddata/CZE_InitialSeedDataSep 1, 2020.csv", seedRadius, deterministic, isCropped = F, level1Names = NULL, DA = F, "observeddata/Ebola_Health_Zones_LatLon.csv", "observeddata/Ebola_Incidence_Data.xlsx", "observeddata/Ebola_Death_Data.xlsx", varCovarFunc = "DBD", QVar, QCorrLength, nbhd, psiDiag)
  #SpatialCompartmentalModelWithDA(model, startDate, selectedCountry, directOutput, rasterAgg, alpha, beta, gamma = gamma/10, sigma, delta, radius, lambda, timestep = 200, seedFile = "seeddata/COD_InitialSeedData.csv", seedRadius, deterministic, isCropped, level1Names, DA = F, "observeddata/Ebola_Health_Zones_LatLon.csv", "observeddata/Ebola_Incidence_Data.xlsx", "observeddata/Ebola_Death_Data.xlsx", varCovarFunc = "DBD", QVar, QCorrLength, nbhd, psiDiag)
#+end_src

* =distwtRaster.R= The Euclidian distance weight matrix function
The file =distwtRaster.R= defines a function =wtd_nbrs_sum=, which calculates a
matrix of values which are weighted sums of values at every cell. The full
source of that file is reproduced here for discussion and analysis.

This sections exists to analyze the reason for the cause of the issue witnessed
in [[Generating the ~I_tilda~ matrix]].

#+begin_comment
,#+begin_quote
This code sets the Euclidean distance and the weight matrix
,#+end_quote

The above quote is a comment on the file when it is sourced in [[source
dependencies]]. The commend doesn't make much sense to me because it does not
"set" a Euclidian distance nor does it "set" a weighted sum in any one variable.
It returns a matrix of values which are weighted sums of values of functions of
the Euclidean distance from a given cell to another cell.
#+end_comment

The average euclidean distance function is implemented as follows in the
original code.

\[
  \displaystyle
  \exp\left( -1 *
    \frac{
      \left(\sum\left(p-q\right)^2\right)^{\frac{1}{2}}
    }{\lambda}
  \right)
\]

#+begin_src R :session *eg*
  avg_euclidean_distance <- function(p, q, lambda)
  {
    exp(-sqrt(sum((p - q)^2))/lambda)
  }
#+end_src

How it is applied, with \(p, q\) being ~c(i,j)~ and ~c(radius+1, radius+1)~,
respectively, is odd in my mind, however.
#+begin_comment
# The remainder of this paragraph was incorrect. The results are okay.
Not only is it odd, it is incorrectly applied for even one dimension, for which
the formula applies. [[https://en.wikipedia.org/wiki/Euclidean_distance#Two_dimensions][We are using two dimensions!]] The point p and the point q
are not separated on just one dimension, but two \(x, y\)!
#+end_comment
I test here the original code and compare it to a slighly modification.

Here is a block to test the original code.

#+name: test the original algorithm in avg_euclidean_distance
#+begin_src R :session *eg* :export both
  library(spatstat.random)

  aed <- function(p, q, lambda) {
    exp(-sqrt((p$x - q$x)^2 + (p$y - q$y)^2)/lambda)
  }

  points <- runifpoint(10, owin(c(0,100), c(0,100)))

  ## Assuming each unit is 5 km, and lambda is (15 km / day) / (5km / cell) = 3 cell / day
  print(aed(points[1], points[2], 3))
#+end_src

#+RESULTS:
: 2.43887270488085e-10

The results of the two slightly different functions are compared for a number of
inputs for verification.

#+name: compare the vectorized and unvectorized form of avg_euclidean_distance
#+begin_src R :session *eg* :export both
  p <- c(points[1]$x, points[1]$y)
  q <- c(points[2]$x, points[2]$y)
  avg_euclidean_distance(p, q, 3)

  avg_euclidean_distance(p, q, 3) == aed(points[1], points[2], 3)
#+end_src

#+RESULTS:
: TRUE

The original code can't handle the class of object I'm using from the
/spatstat.random/ package, of course, which is not expected. It wasn't meant to
handle *any* object type, just numerics. That's not a problem. I saw a potential
problem with ~(p - q)^2~ for vectors, but it looks like it is handled correctly
when using vectors (which suprises me)! Having verified that passing vectors as
\(p, q\) is acceptable I can move on to test other aspects of =wtd_nmbr_sum=
function.

#+name: wtd_nbrs_sum
#+begin_src R
  wtd_nbrs_sum <- function(input_matrix, radius, lambda) {
    temp_1 <- matrix(data = 0, nrow = nrow(x = input_matrix), ncol = radius)
    temp_2 <- matrix(data = 0, nrow = radius, ncol = ((2 * radius) + ncol(x = input_matrix)))
    input_matrix_modified <- rbind(temp_2, cbind(temp_1, input_matrix, temp_1), temp_2)
    output_matrix <- matrix(nrow = nrow(x = input_matrix), ncol = ncol(x = input_matrix))

    ## Generating the weight matrix
    weight_matrix <- matrix(0, nrow = 1 + 2*radius, ncol = 1 + 2*radius)
    for(i in seq_len(1 + 2*radius)) {
      for(j in seq_len(1 + 2*radius)) {
        weight_matrix[i,j] <- avg_euclidean_distance(c(i,j), c(radius+1, radius+1), lambda)
      }
    }

    for(i in seq_len(length.out = nrow(x = input_matrix))) {
      for(j in seq_len(length.out = ncol(x = input_matrix))) {
        row_min <- (radius + (i - radius))
        row_max <- (radius + (i + radius))
        column_min <- (radius + (j - radius))
        column_max <- (radius + (j + radius))
        neighbours <- input_matrix_modified[(row_min:row_max), (column_min:column_max)]
        weighted_sum <- sum(neighbours * weight_matrix) # casewise multiplication
        output_matrix[i, j] <- weighted_sum
      }
    }

    return(output_matrix)
  }
#+end_src

The conclusion of this section, then, is that the ~avg_euclidean_distance~
function was fine, it was just ~wtd_nbrs_sum~ that was bad.

** TODO The new ~averageEuclideanDistance~ function
#+begin_comment
Comment on the use of lambda, the calculation of radius, etc. and the findings
with =radius=, necessarily, being unavailable in the scope of its attempted use
in spatialEpisim.foundation after identifying the discrepancy in the size of the
weight matrix.
#+end_comment

The new ~averageEuclideanDistance~ function's implementation is copied here for comparison.

#+begin_src R :noweb-ref Average Euclidean Distance function from foundation
  <<function documentation>>
  averageEuclideanDistance <-
    function(lambda, aggregationFactor = 1, epsilon = 0) {
      <<constraints on the value of aggregation factor>>

      radius <-
        if (lambda <= aggregationFactor)
          1
        else
          round((lambda - aggregationFactor) / aggregationFactor + epsilon) + 1

      stopifnot(radius %in% seq(floor(radius), ceiling(radius)))

      avg.euc.dist <- function(i, j) {
        exp(-sqrt(sum((c(i, j) - c(radius + 1, radius + 1))^2)) / lambda)
      }

      len <- seq_len(1 + radius * 2)
      weights <-
        dplyr::mutate(
                 tidyr::expand(tibble::tibble(i = len, j = len), i, j),
                 averageEuclideanDistance = purrr::map2_dbl(i, j, avg.euc.dist)
               ) %>%
        dplyr::select(averageEuclideanDistance) %>%
        unlist(use.names = FALSE) %>%
        base::matrix(byrow = TRUE, ncol = sqrt(length(.)))

      <<constraints imposed by terra::focal>>

      return(weights)
    }
#+end_src

The constraints at the end of the function body ensure that when ~terra::focal~
applies the function it is used correctly as a /weights matrix/, which is how
the ~avg_euclidean_distance~ function is used in the original code (in the
construction of a weights matrix). This implementation merely returns the whole
weights matrix from one function. A more appropriate name for this function,
then, might be ~EuclideanDistanceWeights~; nothing is perfect, though.

#+name: constraints imposed by terra::focal
#+begin_src R
  ## NOTE: it is required that the matrix returned is square, and that its
  ## number of rows or columns are odd-numbered.
  stopifnot(dim(weights)[1] == dim(weights)[2])
  stopifnot(dim(weights)[1] %% 2 == 1)
#+end_src

The constraints on the value that ~aggregationFactor~ can take are imposed by
how this factor relates to the size of cells in the raster (the Euclidean plane)
the distances are calculated for. The distances are calculated on a square plane
with roughly or exaclty square cells at the equator, but closer to either pole
of the planet the cells become elongated. This fact is ignored for now; terra
probably has a function to calculate Euclidean distance /perfectly, accounting
for where the origin and destination points are/; if it has one I haven't
understood that from the documentation.

#+name: constraints on the value of aggregation factor
#+begin_src R
  stopifnot(aggregationFactor >= 0)
  if (is.null(aggregationFactor)) aggregationFactor <- 1
  if (aggregationFactor == 0) aggregationFactor <- 1
#+end_src

The function documentation for the ~averageEuclideanDistance~ function from
foundation (spatialEpisim.foundation, that is) is here.

#+begin_src R
  ##' @title Average Euclidean Distance
  ##' @description Measure the exposure influence upon susceptible individuals at
  ##'   spatial position (x, y) of the infectious individuals at a spatial
  ##'   position (u, v).
  ##' @details The 2020 United Nations-adjusted population count raster data, at
  ##'   the 30-arc second resolution, consists of hundreds of thousands (and for
  ##'   some countries millions) of grid cells. This function is used to calculate
  ##'   the average Euclidean distance from one cell to others, adjusting for
  ##'   raster aggregation.
  ##'
  ##'   The mathematical modelling of human or non-human mobility patterns is
  ##'   non-trivial. This function is a limited implementation of the effective
  ##'   area for only human mobility, with distances travelled per day (lambda)
  ##'   measured in kilometers.
  ##'
  ##'   NOTE: Our weight function does not take the same arguments as shown in the
  ##'   slideshow: (w x y u v); The term "effective area" comes from the fact that
  ##'   if the kernel is constant on a finite disk (and zero outside it), then the
  ##'   formula due to Bolker (1999) gives the area of the disk.
  ##'
  ##'   See the article titled *A clarification of transmission terms in
  ##'   host-microparasite models by Begon et al.* (2002).
  ##' @param lambda the average dialy movement distance of an individual (in
  ##'   kilometers).
  ##' @param aggregationFactor the factor of aggregation applied to the raster
  ##'   data mentioned in the function details (expressed in kilometers).
  ##' @param epsilon a rounding error correction (a real number; by default,
  ##'   zero).
  ##' @returns a matrix of the average Euclidean distances
  ##' @export
  ##' @keywords internal
  ##' @author Bryce Carson
  ##' @author Thomas White
  ##' @examples
  ##' averageEuclideanDistance(lambda = 15) # No raster aggregation
  ##' averageEuclideanDistance(lambda = 15, aggregationFactor = 10)
  ##'
  ##' lattice::levelplot(as.array(averageEuclideanDistance(15)))
  ##' lattice::levelplot(as.array(averageEuclideanDistance(100, 35)))
#+end_src

* =rasterPlot.R= Visualization of rasters
The following chunk organizes its children into what constitutes =rasterPlot.R=.
The file is used to plot static plots, which are gathered together into an MP4.

#+begin_src R :noweb no-export
  <<raster-plot-dependencies>>

  #------------------------------------------------------------------------------#
  # R Script Variables                                                           #
  #------------------------------------------------------------------------------#
  # modelSelect <- "SVEIRD"                         # select model from SEIR, SEIRD, SVEIRD
  isoCode <- "COD"                                  # user should pass ISO code as parameter
  year <- 2020                                      # default year (2020)
  resKm <- 1                                        # default resolution (1Km)
  # rasterAgg <- 10                                 # default aggregation factor (10x10)
  PNGFileName <- "susceptible.png"                  # default output file name
  MP4FileName <- "susceptible_MP4.mp4"              # default MP4 file name
  stackLayerFileName <- "susceptible.png"           # default name for arbitrary raster stack PNG TODO: change format to ISO3_Susceptible_0001.png
  # palettePng <- "misc/seminf_haxby.png"             # default colour palette found in misc folder
  colPalette <- c('#FFFFFF', 
                  '#D0D8FB', 
                  '#BAC5F7', 
                  '#8FA1F1', 
                  '#617AEC', 
                  '#0027E0', 
                  '#1965F0', 
                  '#0C81F8', 
                  '#18AFFF', 
                  '#31BEFF', 
                  '#43CAFF', 
                  '#60E1F0', 
                  '#69EBE1', 
                  '#7BEBC8', 
                  '#8AECAE', 
                  '#ACF5A8', 
                  '#CDFFA2', 
                  '#DFF58D', 
                  '#F0EC78', 
                  '#F7D767', 
                  '#FFBD56', 
                  '#FFA044', 
                  '#EE4F4D')
  layerName <- "Susceptible"                        # used to title raster layer plot
  basePopBreaks <- c(0, 10, 25, 50, 100, 250, 1000, 100000) # TODO: dynamically set for each individual country
  aggrPopBreaks <- c(0, 5000, 10000, 25000, 50000, 75000, 100000, 250000, 500000) # TODO: dynamically set for each individual country and aggr level

  #------------------------------------------------------------------------------#
  # R Script Functions (for External Use)                                        #
  #------------------------------------------------------------------------------#

  printStackLayer <- function(rasterStack, rasterLayer, directOutput, Level1Identifier, 
                              selectedCountry, rasterAgg, fname, maxVal, includeLabels, isCropped) {
    # if(missing(fname)) {fname = stackLayerFileName} 
    setUp(isoCode, year, resKm, rasterAgg, fname)               # called to set www/ folder, stack should already be aggregated
    isoCode <<- countrycode(selectedCountry, origin = "country.name", destination = "iso3c")
    rasterAgg <<- rasterAgg
    layerName <<- toString(rasterLayer)                          # alters the plot title
    createPlotPNG(rasterStack[[layerName]], selectedCountry, Level1Identifier, directOutput, maxVal, includeLabels, isCropped)
  }

  <<raster-plot-dead-code-one>>

  setUp <- function(isoCode, year, resKm, rasterAgg, fname) {
    isoCode <<- isoCode
    year <<- year
    resKm <<- resKm
    rasterAgg <<- rasterAgg
    PNGFileName <<- paste0("www/", fname)
    #print(PNGFileName)
    
    #setDirectory()
    #importGeoTiff()
  }

  #------------------------------------------------------------------------------#
  # R Script Functions (for Internal Use)                                        #
  #------------------------------------------------------------------------------#

  #------------------------------------------------------#
  # Creates the base plot .png and outputs to www folder #
  #------------------------------------------------------#
  createPlotPNG <- function(rasterToPrint, selectedCountry, Level1Identifier, directOutput, maxVal, includeLabels, isCropped) {
    is.na(rasterToPrint) <- !rasterToPrint  # used to clear raster values of 0

    x <- classify(rasterToPrint, c(0, 5, 10, 20, 35, 50, 100, 250, 1000, 100000))
    levs <- levels(x)[[1]]
    levels(x) <- levs
    
    pal <- colorRampPalette(colPalette)

    if (!directOutput){
      png(PNGFileName, height = 768, width = 768) # output the plot to the www/ image folder
    }
    
      
    aggrPlotTitle <- paste0("Aggregated ", layerName, " Count \n in ", 
                              selectedCountry, " (", rasterAgg^2 * resKm, 
                              " sq. km resolution)")
      
    terra::plot(x, 
                col=pal(10)[-1], 
                axes = TRUE,
                buffer = TRUE,
                box = TRUE,
                cex.main = 1.5,
                line.main = 1.25,
                main = aggrPlotTitle, 
                xlab = expression(bold(Longitude)),
                ylab = expression(bold(Latitude)),
                line.lab = 2.25,
                cex.lab = 1.5,
                # extra arguments
                all_levels = TRUE,
                zlim=c(0,maxVal),
                plg = list(title = expression(bold("Persons")),
                            title.cex = 1.25,
                            horiz = TRUE, 
                            loc = "bottom",
                            yjust = 3.5,
                            x.intersp = 0.6,
                            inset = c(0, -0.2),
                            cex = 1.25),
                pax = list(cex.axis = 1.7),
                mar = c(12.5, 3.5, 4, 2.5))
    
    terra::plot(Level1Identifier, 
                add = TRUE)
    terra::north(type = 2, xy = "bottomleft", cex = 1)
    
    if (!directOutput){
      dev.off()     # closes the file opened with png(PNGFileName)
      if (!includeLabels){
        img <- image_read(PNGFileName)
        # img <- image_trim(img)
        image_write(img, path=PNGFileName)
      } 
    }
  }

  #---------------------------------------#
  # Sets the working directory for R file #
  #---------------------------------------#
  # setDirectory <- function() {
  #   setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # RStudio IDE required
  #   getwd() # Path to the working directory
  # }

  #-----------------------------------------------#
  # Extracts a palette from a formatted .png file #
  #-----------------------------------------------#
  # getPalette <- function(png) {
  #   raster <- terra::rast(png)
  #   u <- unique(values(raster))
  #   hex <- rgb(u[,1], u[,2], u[,3], maxColorValue = 255)
  #   colorRampPalette(hex)
  # }

  #----------------------------------------------------#
  # Imports the GeoTIFF file into tif folder using FTP #
  #----------------------------------------------------#
  importGeoTiff <- function() {
    url <- paste0("https://data.worldpop.org/GIS/Population/Global_2000_2020_", resKm, "km_UNadj/", 
                 year, "/", toupper(isoCode), "/", tolower(isoCode), "_ppp_", year, "_", resKm,
                 "km_Aggregated_UNadj.tif")
    
    tifFileName <- basename(url)  # name of the .tif file
    foldName <- "tif/"            # .tif files should be stored in local tif/ folder
    
    if (!file.exists(paste0(foldName, tifFileName))){
      download.file(url, paste0(foldName, tifFileName), mode = "wb")
    } 
     WorldPop <<- rast(paste0(foldName, tifFileName))
  }

  #---------------------------------------------------#
  # Sets custom population breaks for a given country #
  #---------------------------------------------------#
  setPopulationBreaks <- function() {
    if (rasterAgg == 0 || rasterAgg == 1){
      toPlot <<- classify(as(WorldPop, "SpatRaster"), basePopBreaks) #raster must be cast to terra spatRaster
      levs <- levels(toPlot)[[1]]
      levs[7] <- "> 1000"
    } else {
      toPlot <<- classify(as(WorldPop_aggr_count, "SpatRaster"), aggrPopBreaks) #raster must be cast to terra spatRaster
      levs <- levels(toPlot)[[1]]
      levs[8] <- "> 250000"
    }
    levels(toPlot) <- levs
  }

  # #---------------------------------------------------------------#
  # # Aggregate the WorldPop raster by specified aggregation factor #
  # #---------------------------------------------------------------#
  # aggregateWorldPop <- function() {
  #   WorldPop_aggr_count <<- terra::aggregate(WorldPop, fact = c(rasterAgg, rasterAgg), fun = sum, na.rm = TRUE)
  #   is.na(WorldPop_aggr_count) <<- !WorldPop_aggr_count # sets cells which are 0 as NA, allows for 0 lower bound in plot
  # }

  # END OF CODE #

  # createMP4(isoCode = "ISR", year = 2020, resKm = 1, rasterAgg = 1, fname = "susceptible_MP4.mp4", iterations = 30)    # example function calls, comment out before calling script
  # createPNG(isoCode = "ISR", year = 2020, resKm = 1, rasterAgg = 1, fname = "susceptible.png") # example function call
  # printStackLayer(rasterStack = ?, rasterLayer = "Susceptible", fname = "susceptible.png", includeLabels = T)
#+end_src

#+name: raster-plot-dependencies
#+begin_src R
  options(conflicts.policy = list(warn = FALSE))
  shhh <- suppressPackageStartupMessages # It's a library, so shhh!
  shhh(library(av))
  shhh(library(countrycode))
  shhh(library(cptcity))
  shhh(library(fasterize))
  shhh(library(lattice))
  shhh(library(magick))
  shhh(library(rasterVis))
  shhh(library(rstudioapi))
  shhh(library(sp))
  shhh(library(sf))     # classes and functions for vector data
  shhh(library(terra, warn.conflicts=FALSE))
#+end_src

#+name: raster-plot-dead-code-one
#+begin_src R
  # createMP4 <- function(isoCode, year, resKm, rasterAgg, fname, iterations) {
  #   n <- 1
  #   while (n <= iterations) { # create the .png files
  #     setUp(isoCode, year, resKm, rasterAgg, paste0("MP4/", isoCode, "_", layerName, "_", sprintf("%04d", n), ".png"))
  #     WorldPop <<- WorldPop*(n/iterations)
  #     setPopulationBreaks()
  #     createPlotPNG(toPlot) 
  #     n <- n + 1 
  #   } 
  #   
  #    setwd("www/MP4")         # create the .mp4 file
  #    av::av_encode_video(list.files(), framerate = 8, output = paste0("../", fname))
  #    setwd("./../..")
  # }

  # createPNG <- function(isoCode, year, resKm, rasterAgg, fname) {
  #   setUp(isoCode, year, resKm, rasterAgg, fname)
  #   if (rasterAgg != 0){
  #     aggregateWorldPop()
  #   }
  #   setPopulationBreaks()
  #   createPlotPNG(toPlot)
  # }
#+end_src

* An R session loading the new code package for use with comparisons :noexport:
This section is not exported to other backends (PDF, HTML, etc.); it would still
be visible on GitHub, as GitHub only does a minimal fancy display of Org files,
but does not render them or support all Org features and syntax.

#+begin_src R :session *foundation*
  library(tidyverse)
  library(terra)
  library(spatialEpisim.foundation)
#+end_src

#+RESULTS:
| sf                       |
| sp                       |
| rstudioapi               |
| rasterVis                |
| magick                   |
| lattice                  |
| fasterize                |
| cptcity                  |
| countrycode              |
| av                       |
| spatialEpisim.foundation |
| terra                    |
| lubridate                |
| forcats                  |
| stringr                  |
| dplyr                    |
| purrr                    |
| readr                    |
| tidyr                    |
| tibble                   |
| ggplot2                  |
| tidyverse                |
| stats                    |
| graphics                 |
| grDevices                |
| datasets                 |
| drat                     |
| devtools                 |
| usethis                  |
| utils                    |
| methods                  |
| base                     |
